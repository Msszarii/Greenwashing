{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/z.askary/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/z.askary/Desktop/Thesis/2. Model/Codes/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "[nltk_data] Downloading package punkt to /Users/z.askary/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/z.askary/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import os\n",
    "%run -i ../helpers.py\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# Download NLTK data files (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Do this once \n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre processing \n",
    "Stop words removal\n",
    "Tokenization etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_splits = pd.read_csv('../data/tp_splits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>q</th>\n",
       "      <th>dt</th>\n",
       "      <th>prep_remarks</th>\n",
       "      <th>QnA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-Q1</td>\n",
       "      <td>2023-02-02 17:00:00</td>\n",
       "      <td>prepared remarks:\\noperator\\ngood day, everyon...</td>\n",
       "      <td>:\\noperator\\ncertainly. we will go ahead and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-Q4</td>\n",
       "      <td>2022-10-27 17:00:00</td>\n",
       "      <td>prepared remarks:\\noperator\\ngood day, and wel...</td>\n",
       "      <td>:\\noperator\\nwe'll go ahead and take our first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-Q3</td>\n",
       "      <td>2022-07-28 17:00:00</td>\n",
       "      <td>prepared remarks:\\noperator\\ngood day, and wel...</td>\n",
       "      <td>:\\noperator\\nwe'll take our first question fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-Q2</td>\n",
       "      <td>2022-04-28 17:00:00</td>\n",
       "      <td>prepared remarks:\\noperator\\ngood day, and wel...</td>\n",
       "      <td>:\\noperator\\nabsolutely. we'll take our first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-Q1</td>\n",
       "      <td>2022-01-27 17:00:00</td>\n",
       "      <td>prepared remarks:\\noperator\\ngood day, and wel...</td>\n",
       "      <td>:\\noperator\\nabsolutely. we'll take our first ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker        q                   dt  \\\n",
       "2821   AAPL  2023-Q1  2023-02-02 17:00:00   \n",
       "3618   AAPL  2022-Q4  2022-10-27 17:00:00   \n",
       "121    AAPL  2022-Q3  2022-07-28 17:00:00   \n",
       "3021   AAPL  2022-Q2  2022-04-28 17:00:00   \n",
       "2345   AAPL  2022-Q1  2022-01-27 17:00:00   \n",
       "\n",
       "                                           prep_remarks  \\\n",
       "2821  prepared remarks:\\noperator\\ngood day, everyon...   \n",
       "3618  prepared remarks:\\noperator\\ngood day, and wel...   \n",
       "121   prepared remarks:\\noperator\\ngood day, and wel...   \n",
       "3021  prepared remarks:\\noperator\\ngood day, and wel...   \n",
       "2345  prepared remarks:\\noperator\\ngood day, and wel...   \n",
       "\n",
       "                                                    QnA  \n",
       "2821  :\\noperator\\ncertainly. we will go ahead and t...  \n",
       "3618  :\\noperator\\nwe'll go ahead and take our first...  \n",
       "121   :\\noperator\\nwe'll take our first question fro...  \n",
       "3021  :\\noperator\\nabsolutely. we'll take our first ...  \n",
       "2345  :\\noperator\\nabsolutely. we'll take our first ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_splits[tp_splits.ticker=='AAPL'][['ticker', 'q','dt' ,'prep_remarks','QnA',]].sort_values('dt', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and ESG Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp_splits = pd.read_csv('./tp_splits_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tp_splits.iloc[0].QnA)\n",
    "#print(tp_splits.iloc[0].QnA_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp_splits.columns\n",
    "tp_splits = tp_splits[['ticker', 'q', 'Sector', 'Industry', 'Shortname',\n",
    "                        'dt', 'prep_remarks', 'QnA']]\n",
    "tp_splits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "\n",
    "finbert_sentiment = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
    "tokenizer_sentiment = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=finbert_sentiment, tokenizer=tokenizer_sentiment)\n",
    "\n",
    "tokenizer_esg = BertTokenizer.from_pretrained('yiyanghkust/finbert-esg', num_labels=4) #do_lower_case=True, add_special_tokens=True, max_length=512, pad_to_max_length=True\n",
    "finbert_esg = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-esg')\n",
    "esg_label_pip = pipeline(\"text-classification\", model=finbert_esg, tokenizer=tokenizer_esg, device=0) # use device CPU\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The tokenizer_esg is initialized with the FinBERT ESG model, which is specifically fine-tuned for ESG-related text classification tasks.\n",
    "# The finbert_esg model is a BERT-based sequence classification model fine-tuned for ESG classification.\n",
    "# The esg_label_pip pipeline combines the tokenizer and model to classify text into ESG categories.\n",
    "# The device parameter is set to 0, which means the pipeline will use GPU if available; otherwise, it will default to CPU.\n",
    "\n",
    "# BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based model designed for natural language understanding tasks.\n",
    "# It uses a bidirectional training approach, which allows it to understand the context of a word based on both its left and right surroundings.\n",
    "# The FinBERT ESG model is a specialized version of BERT, fine-tuned for financial and ESG-related text classification tasks.\n",
    "# The pipeline function simplifies the process of tokenizing input text, passing it through the model, and decoding the output.\n",
    "# The text-classification pipeline is particularly useful for tasks like sentiment analysis, topic classification, and ESG label prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_esg_labels = esg_label_pip(tp_splits['prep_remarks_processed'][0][-2048:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols_expect = ['Environmental','Social','Governance']\n",
    "\n",
    "# Define a function to preprocess text and extract ESG labels and scores(confidence). NAMED ENTITY RECOGNITION\n",
    "def get_esg_label_transcript(tr):\n",
    "    sent_label_scores = []  # Initialize a list to store sentence-level ESG labels and scores\n",
    "\n",
    "    for sent in sent_tokenize(tr):  # Tokenize the transcript into sentences\n",
    "         # if(len(sent)>2048):\n",
    "             # sent = sent[-2048:]\n",
    "        all_esg_labels = esg_label_pip(sent)  # Use the ESG classification pipeline to classify the sentence\n",
    "        non_none_labels = [x for x in all_esg_labels if x['label'] != 'None']  # Filter out labels with 'None'\n",
    "        if len(non_none_labels) > 0:  # If there are valid ESG labels\n",
    "            # Append the label, score, and sentence\n",
    "            sent_label_scores.append([non_none_labels[0]['label'], non_none_labels[0]['score'], sent])  \n",
    "            \n",
    "    # Convert the list of sentence-level labels and scores into a DataFrame\n",
    "    df = pd.DataFrame(sent_label_scores, columns=['esg_label', 'label_score', 'sent'])\n",
    "    return df  # Return the DataFrame\n",
    "\n",
    "# Define a function to calculate sentiments based on ESG labels\n",
    "def create_sentiment_output(all_labels):\n",
    "    non_none_labels = [x for x in all_labels if x['label'] != 'None']  # Filter out labels with 'None'\n",
    "    if len(non_none_labels) > 0:  # If there are valid labels\n",
    "        label = non_none_labels[0]['label']  # Extract the first label\n",
    "        score = non_none_labels[0]['score']  # Extract the corresponding score\n",
    "        # sentiment = 0  # Initialize sentiment score\n",
    "        if label == 'Positive':  # If the label is 'Positive'\n",
    "            return 1 * score  # Return a positive sentiment score\n",
    "        elif label == 'Negative':  # If the label is 'Negative'\n",
    "            return -1 * score  # Return a negative sentiment score  \n",
    "        else:\n",
    "            return 0  # Return neutral sentiment for other labels\n",
    "    else:\n",
    "        return 0  # Return neutral sentiment if no valid labels are found\n",
    "\n",
    "# Define a function to generate ESG columns for a given row in the DataFrame\n",
    "def generate_esg_cols(row, section='transcript'):\n",
    "    # Check if the specified section (e.g., 'prep_remarks' or 'QnA') is not NaN\n",
    "    if row[section] != np.nan:\n",
    "        # Get ESG labels and scores for the transcript using the get_esg_label_transcript function\n",
    "        label_scores_df = get_esg_label_transcript(row[section])\n",
    "        \n",
    "        # Calculate sentiment scores for each sentence in the transcript using the sentiment pipeline\n",
    "        label_scores_df['sentiment'] = label_scores_df.sent.apply(lambda x: create_sentiment_output(sentiment_pipeline(x)))\n",
    "        \n",
    "        # Round sentiment scores to 4 decimal places for consistency\n",
    "        label_scores_df.sentiment = label_scores_df.sentiment.apply(lambda x: np.round(x, 4))\n",
    "        \n",
    "        # Filter sentences with high ESG label scores (> 0.7) and non-zero sentiment scores\n",
    "        clean_scores = label_scores_df[((label_scores_df.label_score > 0.7) & (label_scores_df.sentiment != 0))]\n",
    "        #print(clean_scores.head())\n",
    "        \n",
    "        # Group the filtered sentences by ESG label and calculate the median sentiment score for each label\n",
    "        group_senti = clean_scores.groupby('esg_label')['sentiment'].median().reset_index()\n",
    "        \n",
    "        # Iterate over the ESG labels present in the grouped data\n",
    "        for e in group_senti.esg_label.to_list():\n",
    "            # Assign the median sentiment score for each ESG label to the corresponding column in the row\n",
    "            row[e + '_' + section] = group_senti[group_senti.esg_label == e].sentiment.iloc[0]\n",
    "        \n",
    "        # Identify ESG labels that are missing (not present in the grouped data)\n",
    "        missing_cols = list(set(cols_expect) - set(group_senti.esg_label.to_list()))\n",
    "        \n",
    "        # Assign NaN to the columns corresponding to the missing ESG labels\n",
    "        for c in missing_cols:\n",
    "            row[c + '_' + section] = np.nan\n",
    "    else:\n",
    "        # If the section is NaN, assign NaN to all ESG-related columns\n",
    "        for c in cols_expect:\n",
    "            row[c + '_' + section] = np.nan\n",
    "    \n",
    "    # Return the updated row with the new ESG-related columns\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of ESG labels for a single transcript - prepared remarks or QnA section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tp_splits['QnA'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discover Financial Services\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esg_label</th>\n",
       "      <th>label_score</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Governance</td>\n",
       "      <td>0.533918</td>\n",
       "      <td>john t. greene -- executive vice president, chief financial officer\\nnot so much structurally.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Governance</td>\n",
       "      <td>0.927704</td>\n",
       "      <td>so, there's certainly a very strong governance element.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     esg_label  label_score  \\\n",
       "31  Governance     0.533918   \n",
       "32  Governance     0.927704   \n",
       "\n",
       "                                                                                              sent  \n",
       "31  john t. greene -- executive vice president, chief financial officer\\nnot so much structurally.  \n",
       "32                                         so, there's certainly a very strong governance element.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 188\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(tp_splits.iloc[idx].Shortname)\n",
    "example_df_esg_labels = get_esg_label_transcript(tp_splits['QnA'][idx])\n",
    "example_df_esg_labels[example_df_esg_labels.esg_label=='Governance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esg_label</th>\n",
       "      <th>label_score</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.806470</td>\n",
       "      <td>and if craig is listening, it's been a pleasure working with you too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.497047</td>\n",
       "      <td>now, opportunities in 2021 will dictate how much marketing dollars we ultimately end up spending for new customer acquisition.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.718214</td>\n",
       "      <td>so first is the overall unemployment numbers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.987297</td>\n",
       "      <td>there's about 10.7 million people out of work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.973585</td>\n",
       "      <td>there's another 7.3 million people that aren't included in the unemployment number due to the fact that they haven't actively worked -- looked for work in the past four weeks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.774729</td>\n",
       "      <td>we're going to look specifically at the trajectory of unemployment and the type of unemployment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.977731</td>\n",
       "      <td>so, we're seeing unemployment levels transition from service workers to white collar workers, who would more likely be representative of our customer base and the impact of stimulus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.488067</td>\n",
       "      <td>when i saw the voluntary early retirement, i hope you're a reasonable chunk of that number.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.859147</td>\n",
       "      <td>we tend to keep our rewards program very stable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.487303</td>\n",
       "      <td>it provides a lot of value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.952332</td>\n",
       "      <td>and so, while you've seen competitors make dramatic changes, we feel like our leadership position in cash rewards serves as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.982779</td>\n",
       "      <td>so, getting better line of sight in the direction of white collar employment is probably the most critical one.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.988620</td>\n",
       "      <td>roger and i both talked about white collar employment levels and [speech overlap] will also be new jobless claims.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.570017</td>\n",
       "      <td>now, how much, ultimately, room we have there, uncertain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.724166</td>\n",
       "      <td>if it's been impacted by -- you have a lot of new areas like personal loans, you have buy-now pay-later.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.754214</td>\n",
       "      <td>and could some of these new initiatives and fintechs be more impactful?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.945340</td>\n",
       "      <td>we have activated our procurement organization around third-party spend, and we've driven a lot of productivity through that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.621322</td>\n",
       "      <td>i think i've said goodbye to craig, like at least eight times over the last few decades.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.489998</td>\n",
       "      <td>there's a lot of changes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.915127</td>\n",
       "      <td>with all of the innovation in the market, where is discover investing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.711267</td>\n",
       "      <td>if the world is coming your way, you've got to keep moving to stay ahead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.971318</td>\n",
       "      <td>we've always stood for innovation back to our founding and inventing credit card rewards, but more recently with everything from the fico score on statements, ability to freeze your account.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.906424</td>\n",
       "      <td>and so, you can rest assure that that focus is still there on a pipeline of customer-driven innovation across all of our products.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.932652</td>\n",
       "      <td>there's a lot of times we are getting commentary or questions around, well, the millennials are not going to borrow on their credit cards the way others did.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.521616</td>\n",
       "      <td>do you feel there's anything to the thought that the millennials will be less likely to use credit cards?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>roger c. hochschild -- director, chief executive officer and president\\nso, in terms of millennials, based on the data we see, we're either the leading or one of the leading underwriters for college students.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.974024</td>\n",
       "      <td>we have college students and young adults that appreciate sort of the leading digital functionality, as well as some of the innovations i talked about.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.575277</td>\n",
       "      <td>and part of the advantage we had, we have been tightening for a number of years coming into this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.881918</td>\n",
       "      <td>and then there's a new administration and then maybe some changing policy or some thoughts about potential changing policy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.569841</td>\n",
       "      <td>but i feel good about the products we have, and we have a great team on it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.979438</td>\n",
       "      <td>there's a science to it, and then there is a level of professional judgment or art to it as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.559527</td>\n",
       "      <td>companies started talking about we'll do half, about a third for growth, a third for capital return, a third for investment in technology, something like that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.822425</td>\n",
       "      <td>a lot of it is about spending smart, not just putting huge amounts of money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Social</td>\n",
       "      <td>0.360490</td>\n",
       "      <td>we go through an annual capital planning process here as most financial services institutions do.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   esg_label  label_score  \\\n",
       "0     Social     0.806470   \n",
       "1     Social     0.497047   \n",
       "2     Social     0.718214   \n",
       "3     Social     0.987297   \n",
       "4     Social     0.973585   \n",
       "5     Social     0.774729   \n",
       "6     Social     0.977731   \n",
       "7     Social     0.488067   \n",
       "8     Social     0.859147   \n",
       "9     Social     0.487303   \n",
       "10    Social     0.952332   \n",
       "11    Social     0.982779   \n",
       "12    Social     0.988620   \n",
       "13    Social     0.570017   \n",
       "14    Social     0.724166   \n",
       "15    Social     0.754214   \n",
       "16    Social     0.945340   \n",
       "17    Social     0.621322   \n",
       "18    Social     0.489998   \n",
       "19    Social     0.915127   \n",
       "20    Social     0.711267   \n",
       "21    Social     0.971318   \n",
       "22    Social     0.906424   \n",
       "23    Social     0.932652   \n",
       "24    Social     0.521616   \n",
       "25    Social     0.978763   \n",
       "26    Social     0.974024   \n",
       "27    Social     0.575277   \n",
       "28    Social     0.881918   \n",
       "29    Social     0.569841   \n",
       "33    Social     0.979438   \n",
       "34    Social     0.559527   \n",
       "35    Social     0.822425   \n",
       "36    Social     0.360490   \n",
       "\n",
       "                                                                                                                                                                                                                sent  \n",
       "0                                                                                                                                              and if craig is listening, it's been a pleasure working with you too.  \n",
       "1                                                                                     now, opportunities in 2021 will dictate how much marketing dollars we ultimately end up spending for new customer acquisition.  \n",
       "2                                                                                                                                                                      so first is the overall unemployment numbers.  \n",
       "3                                                                                                                                                                     there's about 10.7 million people out of work.  \n",
       "4                                    there's another 7.3 million people that aren't included in the unemployment number due to the fact that they haven't actively worked -- looked for work in the past four weeks.  \n",
       "5                                                                                                                   we're going to look specifically at the trajectory of unemployment and the type of unemployment.  \n",
       "6                             so, we're seeing unemployment levels transition from service workers to white collar workers, who would more likely be representative of our customer base and the impact of stimulus.  \n",
       "7                                                                                                                        when i saw the voluntary early retirement, i hope you're a reasonable chunk of that number.  \n",
       "8                                                                                                                                                                   we tend to keep our rewards program very stable.  \n",
       "9                                                                                                                                                                                        it provides a lot of value.  \n",
       "10                                                                                 and so, while you've seen competitors make dramatic changes, we feel like our leadership position in cash rewards serves as well.  \n",
       "11                                                                                                   so, getting better line of sight in the direction of white collar employment is probably the most critical one.  \n",
       "12                                                                                                roger and i both talked about white collar employment levels and [speech overlap] will also be new jobless claims.  \n",
       "13                                                                                                                                                         now, how much, ultimately, room we have there, uncertain.  \n",
       "14                                                                                                          if it's been impacted by -- you have a lot of new areas like personal loans, you have buy-now pay-later.  \n",
       "15                                                                                                                                           and could some of these new initiatives and fintechs be more impactful?  \n",
       "16                                                                                     we have activated our procurement organization around third-party spend, and we've driven a lot of productivity through that.  \n",
       "17                                                                                                                          i think i've said goodbye to craig, like at least eight times over the last few decades.  \n",
       "18                                                                                                                                                                                         there's a lot of changes.  \n",
       "19                                                                                                                                            with all of the innovation in the market, where is discover investing?  \n",
       "20                                                                                                                                         if the world is coming your way, you've got to keep moving to stay ahead.  \n",
       "21                    we've always stood for innovation back to our founding and inventing credit card rewards, but more recently with everything from the fico score on statements, ability to freeze your account.  \n",
       "22                                                                                and so, you can rest assure that that focus is still there on a pipeline of customer-driven innovation across all of our products.  \n",
       "23                                                     there's a lot of times we are getting commentary or questions around, well, the millennials are not going to borrow on their credit cards the way others did.  \n",
       "24                                                                                                         do you feel there's anything to the thought that the millennials will be less likely to use credit cards?  \n",
       "25  roger c. hochschild -- director, chief executive officer and president\\nso, in terms of millennials, based on the data we see, we're either the leading or one of the leading underwriters for college students.  \n",
       "26                                                           we have college students and young adults that appreciate sort of the leading digital functionality, as well as some of the innovations i talked about.  \n",
       "27                                                                                                                 and part of the advantage we had, we have been tightening for a number of years coming into this.  \n",
       "28                                                                                       and then there's a new administration and then maybe some changing policy or some thoughts about potential changing policy.  \n",
       "29                                                                                                                                       but i feel good about the products we have, and we have a great team on it.  \n",
       "33                                                                                                                 there's a science to it, and then there is a level of professional judgment or art to it as well.  \n",
       "34                                                   companies started talking about we'll do half, about a third for growth, a third for capital return, a third for investment in technology, something like that.  \n",
       "35                                                                                                                                      a lot of it is about spending smart, not just putting huge amounts of money.  \n",
       "36                                                                                                                 we go through an annual capital planning process here as most financial services institutions do.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df_esg_labels[example_df_esg_labels.esg_label=='Social']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_columns', 0) \n",
    "pd.reset_option('display.max_colwidth', 0)\n",
    "# tp_splits.head(1).apply(lambda x: generate_esg_cols(x,'prep_remarks'), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement run for a single company\n",
    "\n",
    "Very resource intensive need to find ways to run it locally with garbage collection and parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_splits.head(1).apply(lambda x: generate_esg_cols(x,'QnA'), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for few companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# Sample 10 tickers for testing\n",
    "np.random.seed(10)\n",
    "sample_tics = np.random.choice(tp_splits.ticker.unique(),10)\n",
    "# print(f'Sample Tickers: '+str(sample_tics))\n",
    "# tp_splits.head().apply(generate_esg_cols, axis=1)\n",
    "# get_esg_label_transcript(tp_splits.iloc[0]['prep_remarks'])\n",
    "\n",
    "def generate_esg_cols_sections(tic):\n",
    "    \"\"\"\n",
    "    Processes ESG labels and sentiments for a given ticker's data.\n",
    "\n",
    "    Args:\n",
    "        tic (str): The ticker symbol of the company.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with ESG labels and sentiment scores for the specified ticker.\n",
    "    \"\"\"\n",
    "    df = tp_splits[tp_splits.ticker == tic]\n",
    "    try:\n",
    "        # Apply ESG label generation for 'prep_remarks' and 'QnA' sections\n",
    "        df = df.apply(lambda x: generate_esg_cols(x, 'prep_remarks'), axis=1)\n",
    "        df = df.apply(lambda x: generate_esg_cols(x, 'QnA'), axis=1)\n",
    "        #print(df)\n",
    "        #input()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return df\n",
    "    return df\n",
    "\n",
    "def process_ticker(tic):\n",
    "    if not exists(f'./tickers/{tic}.csv'):\n",
    "        print(f'running for: {tic}')\n",
    "        df = generate_esg_cols_sections(tic)\n",
    "        df.to_csv(f'./tickers/{tic}.csv', index=None)\n",
    "        del df\n",
    "        gc.collect()\n",
    "        \n",
    "# for tic in sample_tics:\n",
    "for tic in tp_splits.ticker.unique():\n",
    "    \"\"\"\n",
    "    Iterates over a list of sample tickers, processes ESG data for each ticker,\n",
    "    and saves the results to a CSV file if it doesn't already exist.\n",
    "\n",
    "    Args:\n",
    "        sample_tics (list): A list of ticker symbols to process.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not exists(f'./tickers/{tic}.csv'):\n",
    "        # with Pool(processes=4) as pool:  # Adjust the number of processes as needed\n",
    "            # pool.map(process_ticker, tp_splits.ticker.unique())\n",
    "        print(f'running for: {tic}')\n",
    "        # Call the function to process ESG data for the ticker\n",
    "        df = generate_esg_cols_sections(tic)\n",
    "        # Save the processed DataFrame to a CSV file\n",
    "        df.to_csv(f'./tickers/{tic}.csv', index=None, sep=';')\n",
    "        # Clean up memory\n",
    "        del df\n",
    "        # Force garbage collection to free up memory\n",
    "        gc.collect()\n",
    "    else:\n",
    "        print(f'File already exists for {tic}, skipping...')\n",
    "        continue\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
